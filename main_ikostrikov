from torch import optim
import gym_super_mario_bros
from nes_py.wrappers import JoypadSpace
from Environment_wrappers.wrappers import ResizeAndGrayscale, IntrinsicWrapper

from ICM.ICM import ICM
from ICM.ICM_buffer import ICMBuffer
from Agents.neural_network import ActorCritic
from Logger.custom_sb3_loggers import A2cLogger

from stable_baselines3.a2c.a2c import A2C
from stable_baselines3.common.atari_wrappers import MaxAndSkipEnv

from Config import ENV_CFG, ICM_CFG, A2C_CFG
from Config.all_hyperparams_dict import HYPERPARAMS

from a2c_ppo_acktr import algo
from a2c_ppo_acktr.train import train

import wandb

import torch
import random
import numpy as np

if ENV_CFG.SEED != -1:
    torch.manual_seed(ENV_CFG.SEED)
    random.seed(ENV_CFG.SEED)
    np.random.seed(ENV_CFG.SEED)
    torch.backends.cudnn.benchmark = False
    #torch.use_deterministic_algorithms(mode = True)

run = wandb.init(project = "Mario", config = HYPERPARAMS)


env = gym_super_mario_bros.make('SuperMarioBros-v0')
env = JoypadSpace(env, ENV_CFG.ALL_ACTION_SPACE)
action_dim = env.action_space.n
icm = ICM(action_dim, temporal_channels = ENV_CFG.TEMPORAL_CHANNELS, 
    hidden_layer_neurons=ICM_CFG.HIDDEN_LAYERS, eta = ICM_CFG.ETA, feature_map_qty=ICM_CFG.FMAP_QTY
    ).to(ENV_CFG.DEVICE).train()
icm_optimizer = optim.Adam(icm.parameters(), lr=ICM_CFG.LR)
icm_buffer = ICMBuffer(ICM_CFG.BATCH_SIZE, ICM_CFG.BUFFER_SIZE)

env = MaxAndSkipEnv(env, skip=ENV_CFG.ACTION_SKIP)
env = ResizeAndGrayscale(env, ENV_CFG.RESIZED_SIZE, ENV_CFG.TEMPORAL_CHANNELS)
env = IntrinsicWrapper(env, ENV_CFG.ACTION_SPACE_SIZE, motivation_model = icm, optimizer_of_model = icm_optimizer, 
                       buffer = icm_buffer, motivation_only = True, beta_coef=ICM_CFG.BETA,
                       fps = ENV_CFG.FPS)

train(env, 1, ENV_CFG.DEVICE, A2C_CFG.VALUE_LOSS_COEF, A2C_CFG.ENTROPY_COEF, A2C_CFG.LR)