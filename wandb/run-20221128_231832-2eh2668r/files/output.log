Using cuda device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
Previous observation shape: torch.Size([1, 3, 42, 42])
Action shape: torch.Size([1])
New observation shape: torch.Size([1, 3, 42, 42])
Quantity of classes: 12
Action shape before: torch.Size([1])
State shape: torch.Size([1, 64])
Action shape after: torch.Size([1, 12])
ICM reward: (tensor([[0.0827, 0.0876, 0.0836, 0.0784, 0.0831, 0.0858, 0.0777, 0.0893, 0.0797,
         0.0876, 0.0832, 0.0815]], device='cuda:0', grad_fn=<SoftmaxBackward0>), tensor([[ 0.0155,  0.0772, -0.0027,  0.0069, -0.0993, -0.0891,  0.0822,  0.0715,
         -0.0406,  0.0397, -0.0068, -0.1062,  0.0413, -0.0615,  0.0081, -0.0015,
         -0.0508, -0.0081, -0.0513, -0.0631,  0.0147,  0.0758, -0.0921, -0.0753,
         -0.0219, -0.0410, -0.0648,  0.0010,  0.1116, -0.0416,  0.0706, -0.0140,
         -0.0380, -0.0326, -0.0679,  0.0153, -0.0097,  0.0438, -0.0533,  0.0701,
          0.0147,  0.0759, -0.0176, -0.0762, -0.0012,  0.0801,  0.0832,  0.0487,
          0.1042, -0.0344,  0.1330, -0.0160,  0.0581,  0.0833,  0.0186,  0.0410,
          0.0018, -0.0710, -0.0378, -0.0595,  0.0389, -0.1251,  0.0235,  0.0800]],
       device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[ 0.0382,  0.0170, -0.5245,  0.1143,  0.0387, -0.2911,  0.0025,  0.1172,
         -0.7532,  0.0422,  0.1277,  0.7460,  0.3666,  0.5287, -0.0882, -0.2058,
          0.0563, -0.0114, -0.0159, -0.1439, -0.0770, -0.0310, -0.2742, -0.0274,
          0.0322, -0.1005,  0.0761,  0.2552, -0.0172, -0.8088,  0.0120, -0.0150,
          0.5458,  0.1155,  0.9704, -0.1623,  0.4298, -0.1018,  0.0273,  0.3066,
         -0.0627, -0.0807,  0.0084, -0.0609,  0.2694, -0.2602,  0.0017, -0.8025,
         -0.1821,  0.2760, -0.1208,  0.6539, -0.0436, -0.2342,  0.1776,  0.6433,
          0.5761, -0.0757,  0.0845, -0.0185,  0.0762,  0.0062, -0.0190, -0.0492]],
       device='cuda:0'))
Random indicies are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Quantity of classes: 12
Action shape before: torch.Size([32])
State shape: torch.Size([32, 64])
Action shape after: torch.Size([32, 12])
ICM loss value: 2.7857589721679688
TypeError: float() argument must be a string or a number, not 'tuple'
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/home/dvasilev/mario_icm/main.py", line 38, in <module>
    model.learn(total_timesteps=10_000_000)
  File "/home/dvasilev/mario_icm/.conda/lib/python3.9/site-packages/stable_baselines3/a2c/a2c.py", line 203, in learn
    return super().learn(
  File "/home/dvasilev/mario_icm/.conda/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 262, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/dvasilev/mario_icm/.conda/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 181, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/dvasilev/mario_icm/.conda/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 162, in step
    return self.step_wait()
  File "/home/dvasilev/mario_icm/.conda/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_transpose.py", line 95, in step_wait
    observations, rewards, dones, infos = self.venv.step_wait()
  File "/home/dvasilev/mario_icm/.conda/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 43, in step_wait
    obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(
ValueError: setting an array element with a sequence.